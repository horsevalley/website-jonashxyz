[{"content":"The relationship between nodes and pods In Kubernetes, the relationship between nodes and pods is central to how applications are deployed and managed. Understanding what nodes and pods are, individually, helps clarify their interaction.\nWhat are Pods? A pod is the smallest deployable unit in Kubernetes and serves as a wrapper for one or more containers. Each pod is designed to run a single instance of a given application or service. It can contain one or multiple containers (usually Docker containers), and these containers within a pod share resources like networking and storage. Containers in the same pod can communicate with each other using localhost, as they share the same network namespace.\nPods encapsulate:\nApplication containers Storage resources A unique network IP Options that govern how the container(s) should run A pod is designed to run a single instance of a given application. If your application requires scaling, you create multiple instances of the same pod, each of which might be identical but isolated from others.\nWhat are Nodes? A node is a worker machine in a Kubernetes cluster. This machine can be either a physical computer or a virtual machine (VM) depending on the environment in which the Kubernetes cluster is deployed. Each node is managed by the master components (such as the scheduler, API server, and controller manager), which make decisions about where to place pods, monitor node and pod status, and respond to changes in the cluster. Nodes have the necessary services to run pods, including the Docker runtime and the Kubelet, which is responsible for maintaining a set of pods as specified by the Kubernetes API.\nEach node in a Kubernetes cluster fulfills one or more of the following roles:\nMaster Node: Runs cluster management tasks. Worker Node: Hosts the Pods that are the components of the application workload. Nodes are responsible for providing the resources (CPU, memory, network, and storage) that pods need to run their applications.\nRelationship between Nodes and Pods Nodes provide the runtime environments for pods. Each node can host multiple pods. Pods are assigned to nodes by the Kubernetes scheduler based on resource availability, policy, and other constraints. Each pod is bound to a node and remains on that node until terminated or deleted. If a node fails, the pods scheduled on that node are scheduled for deletion, and they may be recreated by the control plane on other nodes. This relationship enables Kubernetes to manage large-scale, distributed environments efficiently, ensuring that applications are reliably available and can be scaled as needed across the various nodes in the cluster.\nLinks: 202405142258\nKubernetes documentation home: https://kubernetes.io/docs/home/\n","permalink":"https://jonash.xyz/posts/kubernetes---understanding-the-relationship-between-nodes-and-pods/","summary":"The relationship between nodes and pods In Kubernetes, the relationship between nodes and pods is central to how applications are deployed and managed. Understanding what nodes and pods are, individually, helps clarify their interaction.\nWhat are Pods? A pod is the smallest deployable unit in Kubernetes and serves as a wrapper for one or more containers. Each pod is designed to run a single instance of a given application or service.","title":"Kubernetes - understanding the relationship between nodes and pods"},{"content":"Convert SVG to PDF Today I learned that if you have Inkscape installed on your machine, you can convert .SVG files into .PDF, using this simple command:\ninkscape input.svg --export-filename=output.pdf\nReplace input.svg with the name of your SVG file and output.pdf with the desired output PDF file name. Example use case Say you have developed a drawing or mindmap in Excalidraw. You can export this to SVG and then run the command to convert it to PDF. Very cool!\nLinks : 202403241251\n","permalink":"https://jonash.xyz/posts/convert-svg-to-pdf-using-inkscape/","summary":"Convert SVG to PDF Today I learned that if you have Inkscape installed on your machine, you can convert .SVG files into .PDF, using this simple command:\ninkscape input.svg --export-filename=output.pdf\nReplace input.svg with the name of your SVG file and output.pdf with the desired output PDF file name. Example use case Say you have developed a drawing or mindmap in Excalidraw. You can export this to SVG and then run the command to convert it to PDF.","title":"Convert SVG to PDF Using Inkscape"},{"content":"obsidian-sync-github Why write this script? I\u0026rsquo;m using Arch Linux and the Obsidian electron AppImage from AUR. It works great, but for some reason the obsidian git community plugin makes the app super sluggish. I removed the plugin and wrote my own bash script instead.\nHow the script works Auto-pushes Obsidian notes to GitHub via a cronjob every 30 minutes crontab -e -\u0026gt; */30 * * * * /home/jonash/.local/bin/obsidian-sync-github Sends a notification via dunstify and your e-mail address of choice #!/bin/bash # Navigate to your repository directory cd ~/obsidian/ # Add all changes to git git add . # Commit the changes with a current timestamp git commit -m \u0026#34;Automated commit on $(date)\u0026#34; # Push the changes git push origin main # Send notification after the push is sent if git push origin main; then # Check if dunstify is available (dunst\u0026#39;s notification tool) if command -v dunstify \u0026gt;/dev/null 2\u0026gt;\u0026amp;1; then # Send a notification dunstify \u0026#34;Successfully pushed obsidian notes to GitHub!\u0026#34; else echo \u0026#34;dunstify not found, cannot send notification\u0026#34; fi # Email details recipient=\u0026#34;jonash@jonash.xyz\u0026#34; subject=\u0026#34;Subject: Obsidian Notes Push Successful\u0026#34; body=\u0026#34;Your Obsidian notes have been successfully pushed to GitHub on $(date)\u0026#34; # Send the email echo -e \u0026#34;$subject\\n\\n$body\u0026#34; | msmtp \u0026#34;$recipient\u0026#34; else echo \u0026#34;git push failed\u0026#34; fi ","permalink":"https://jonash.xyz/posts/obsidian-sync-github-script/","summary":"obsidian-sync-github Why write this script? I\u0026rsquo;m using Arch Linux and the Obsidian electron AppImage from AUR. It works great, but for some reason the obsidian git community plugin makes the app super sluggish. I removed the plugin and wrote my own bash script instead.\nHow the script works Auto-pushes Obsidian notes to GitHub via a cronjob every 30 minutes crontab -e -\u0026gt; */30 * * * * /home/jonash/.local/bin/obsidian-sync-github Sends a notification via dunstify and your e-mail address of choice #!","title":"Obsidian Sync Github Script"},{"content":"What is HUGO? HUGO is a framework, designed to convert code and content into static websites. It is written in Go, making it exceptionally fast at compiling websites, even those with thousands of pages. Here\u0026rsquo;s how it works:\nFast and Efficient: HUGO takes your content, which you can write in Markdown (a lightweight markup language), and your templates, which define the structure and design of your site, and combines them to generate a complete, static website. These websites are made up of prebuilt HTML files, making them very fast to load and easy to host.\nNo Database Required: Unlike dynamic site generators that require databases to store your site\u0026rsquo;s content, HUGO works with files only. This means your website\u0026rsquo;s content and layout are defined through text files, templates, and configurations without needing a database. This simplicity leads to increased security and ease of maintenance.\nCustomizable: HUGO is highly customizable, allowing you to create websites that range from blogs and portfolios to documentation and company websites, all while providing a wide range of themes and plugins to enhance functionality and appearance.\nLive Reloading: It offers a live reload feature, which means you can see the changes you make in real-time as you develop your site. This makes the development process more intuitive and faster.\nStatic Site Benefits: Since HUGO generates static websites, these sites are inherently secure, fast, and reliable. They can be hosted on any web server or services like GitHub Pages, Netlify, and Vercel, often with little to no cost for hosting.\nIn essence, HUGO is a tool that helps developers and content creators build websites quickly and efficiently, without worrying about databases or server-side scripting, making it an excellent choice for projects where speed, security, and simplicity are prioritized.\nStep 1: Install HUGO Windows: Use Chocolatey: choco install hugo -confirm macOS: Use Homebrew: brew install hugo Linux: Use your distro\u0026rsquo;s package manager, for example, sudo apt-get install hugo for Ubuntu. Step 2: Create a New Site Open a terminal or command prompt. Navigate to the directory where you want your site. Run hugo new site mywebsite -f \u0026quot;yaml\u0026quot; - replacing mywebsite with your desired site name. Step 3: Add a Theme Find a theme you like from HUGO Themes. Clone the theme into your project: e.g. git clone https://github.com/reorx/hugo-PaperModX themes/PaperModX --depth=1 Add the theme to your site\u0026rsquo;s config file: echo 'theme : nameOfYourTheme' \u0026gt;\u0026gt; config.yml e.g. echo 'theme: PaperModX' \u0026gt;\u0026gt; config.yml you can remove the hugo.toml file, since we are using yaml config instead Step 4: Add Content cd into the archetypes folder and replace the contents of defaults.md with the following code: --- title : \u0026#39;{{ replace .File.ContentBaseName \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#39; date : {{ .Date }} draft : false --- Create a new post: hugo new posts/my-first-post.md Open the file in a text editor, and you\u0026rsquo;ll see some front matter at the top. Below this, add your content. Step 5: Start the HUGO Server Run hugo server in your site directory. Open a web browser and go to http://localhost:1313 to see your site. Step 6: Build Your Site When ready to publish, run hugo to build your static site. The output will be in the public directory, ready to be deployed to your hosting provider. I have added an alias, to my .zshrc file, to update my website after building with the hugo command, with the help of rsync: update_website=\u0026#34;rsync -vrP --delete-after /home/jonash/dotfiles/website/website/jonashxyz/public/ root@jonash.xyz:/var/www/jonashxyz/\u0026#34; \\ I got the alias from Luke Smith Done Congratulations! You\u0026rsquo;ve just created a website with HUGO. For more detailed instructions, visit the official HUGO documentation.\nAlso, read the documentation of your chosen theme, e.g. PaperModX.\nEnjoy!\nLinks:\n202403081313\n","permalink":"https://jonash.xyz/posts/generate-a-website-with-hugo/","summary":"What is HUGO? HUGO is a framework, designed to convert code and content into static websites. It is written in Go, making it exceptionally fast at compiling websites, even those with thousands of pages. Here\u0026rsquo;s how it works:\nFast and Efficient: HUGO takes your content, which you can write in Markdown (a lightweight markup language), and your templates, which define the structure and design of your site, and combines them to generate a complete, static website.","title":"Create Your Own Website With HUGO"},{"content":"Unshackle Your Digital Life Get a Google Pixel phone, so you can install GrapheneOS. I recommend Google Pixel 6a. Very cheap and very good. Get rid of all the apps you don\u0026rsquo;t need Sync your data with SyncThing Create your own NextCloud server Use VimWiki/Obsidian + vim/neovim to take notes in markdown, and take full ownership over your own data Use Linux on your personal computer(s) Use pass to store your accounts/passwords Don\u0026rsquo;t let proprietary software take your money and own YOUR data Never look back ","permalink":"https://jonash.xyz/posts/how-to-live-an-unshackled-digital-life/","summary":"Unshackle Your Digital Life Get a Google Pixel phone, so you can install GrapheneOS. I recommend Google Pixel 6a. Very cheap and very good. Get rid of all the apps you don\u0026rsquo;t need Sync your data with SyncThing Create your own NextCloud server Use VimWiki/Obsidian + vim/neovim to take notes in markdown, and take full ownership over your own data Use Linux on your personal computer(s) Use pass to store your accounts/passwords Don\u0026rsquo;t let proprietary software take your money and own YOUR data Never look back ","title":"Unshackle Your Digital Life"},{"content":"First of all, what is GRUB? GRUB is a boot loader, which lets you boot up your system. The abbreviation stands for GNU GRand Unified Bootloader, and is a boot loader package from the GNU Project. GRUB is the primary bootloader for many Linux distributions, allowing users to choose from multiple operating systems or different versions of the same operating system at boot time. It\u0026rsquo;s designed to be highly configurable and supports a wide range of operating systems, not just Linux.\nWhy make this guide? The reason I made this simple guide is so you know what to do when you get to Arch Linux installation guide, chapter 3.8.\nGRUB features include: The ability to boot multiple operating systems, including Linux, Windows, and macOS. Support for reading data from various file systems, allowing it to load boot files from these file systems directly. A flexible and powerful command-line interface that can be used to troubleshoot boot issues. The capability to load operating systems from a network, which is particularly useful in managed IT environments. A customizable menu interface that can display graphics and themes, allowing for a visually appealing boot menu. GRUB has evolved over time, with GRUB 2 being the successor to the original GRUB (referred to as GRUB Legacy). GRUB 2 offers improved modularity, portability, and features compared to its predecessor.\nInstalling GRUB EFI in Arch Linux First off, we install some packages:\nsudo pacman -S vim networkmanager grub efibootmgr dosfstools os-prober mtools (Networkmanager is optional, but highly recommended)\nEnableNetworkManager systemctl enable NetworkManager Mount EFI-partition mount --mkdir /dev/drive /boot/EFI Install GRUB grub-install --target=x86_64-efi --bootloader-id=grub_uefi --efi-directory=/boot/EFI --no-nvram --removable --recheck Make grub config file grub-mkconfig -o /boot/grub/grub.cfg Reboot Exit the chroot environment by typing exit or pressing Ctrl+d. Optionally manually unmount all the partitions with umount -R /mnt: this allows noticing any \u0026ldquo;busy\u0026rdquo; partitions, and finding the cause Finally, restart the machine by typing reboot: any partitions still mounted will be automatically unmounted by systemd. Remember to remove the installation medium and then login into the new system with the root account ","permalink":"https://jonash.xyz/posts/grub-bootloader/","summary":"First of all, what is GRUB? GRUB is a boot loader, which lets you boot up your system. The abbreviation stands for GNU GRand Unified Bootloader, and is a boot loader package from the GNU Project. GRUB is the primary bootloader for many Linux distributions, allowing users to choose from multiple operating systems or different versions of the same operating system at boot time. It\u0026rsquo;s designed to be highly configurable and supports a wide range of operating systems, not just Linux.","title":"GRUB Bootloader"},{"content":"These modern Linux tools might enhance your workflow fd is a simple and fast file search tool, enhancing the Unix find command. exa is a modern replacement for ls, enhancing file listing with better defaults. dog is a modern, feature-rich DNS client for the command-line. ncdu is a console disk usage analyzer for quick space management. bat is a cat clone with syntax highlighting and Git integration for the command-line. sd is a simple and intuitive find-and-replace CLI tool, aiming to improve upon sed. dust visualizes disk usage with an emphasis on clarity, acting as a more intuitive du. xh is a friendly and fast HTTP client for the terminal, inspired by curl and HTTPie. dufis a modern disk usage utility for the command-line with an intuitive interface. ","permalink":"https://jonash.xyz/posts/modern-linux-tools/","summary":"These modern Linux tools might enhance your workflow fd is a simple and fast file search tool, enhancing the Unix find command. exa is a modern replacement for ls, enhancing file listing with better defaults. dog is a modern, feature-rich DNS client for the command-line. ncdu is a console disk usage analyzer for quick space management. bat is a cat clone with syntax highlighting and Git integration for the command-line. sd is a simple and intuitive find-and-replace CLI tool, aiming to improve upon sed.","title":"Modern Linux Tools"},{"content":"Demystifying Cloud Engineering Cloud engineering is the application of engineering disciplines to cloud computing. It brings a systematic approach to the high-level concerns of commercialization, standardization, and governance in conceiving, developing, operating, and maintaining cloud computing systems. It is a multidisciplinary method that encompasses contributions from diverse areas such as systems engineering, software engineering, web engineering, and database engineering.\nKey Components of Cloud Engineering Cloud Infrastructure: Design and management of the physical and virtual resources necessary for cloud computing.\nCloud Software Development: Building, deploying, and managing software applications that are hosted on cloud platforms.\nCloud Security: Protecting cloud-based systems, data, and infrastructure from cybersecurity threats.\nDevOps in the Cloud: Integrating development and operations teams to improve collaboration and productivity by automating infrastructure, workflows, and continuously measuring application performance.\nBenefits of Cloud Engineering Scalability: Easy to scale computing resources up or down based on demand, ensuring flexibility and cost-effectiveness.\nCost Efficiency: Reduces the need for significant upfront investment in IT infrastructure and decreases the cost of IT management and maintenance.\nInnovation: Facilitates rapid development, testing, and deployment of applications, allowing for faster innovation and time to market.\nReliability: Offers reliable services with data backup, disaster recovery, and redundancy features to ensure continuous operation.\nBest Practices in Cloud Engineering Emphasize Security: Implement robust security measures, including identity and access management, encryption, and security protocols.\nOpt for Multi-Cloud and Hybrid Cloud Strategies: Utilize multiple cloud service providers or a combination of public and private clouds to avoid vendor lock-in and enhance business continuity.\nMonitor and Manage Performance: Continuously monitor cloud resources and applications to optimize performance, reduce costs, and improve customer satisfaction.\nAdopt Automation: Leverage automation for provisioning, deployment, scaling, and management tasks to increase efficiency and reduce human errors.\nConclusion Cloud engineering is a vital field in today\u0026rsquo;s digital landscape, offering scalable, flexible, and cost-effective solutions for businesses. By understanding and applying the principles of cloud engineering, organizations can leverage the full potential of cloud computing to innovate, grow, and stay competitive in the rapidly evolving technology market.\n","permalink":"https://jonash.xyz/posts/cloud-engineering/","summary":"Demystifying Cloud Engineering Cloud engineering is the application of engineering disciplines to cloud computing. It brings a systematic approach to the high-level concerns of commercialization, standardization, and governance in conceiving, developing, operating, and maintaining cloud computing systems. It is a multidisciplinary method that encompasses contributions from diverse areas such as systems engineering, software engineering, web engineering, and database engineering.\nKey Components of Cloud Engineering Cloud Infrastructure: Design and management of the physical and virtual resources necessary for cloud computing.","title":"Cloud Engineering"},{"content":"From darkness to light In winter\u0026rsquo;s clutch, the world lay still,\nA canvas painted in shades of chill.\nThe trees stood bare, the skies so gray,\nHope seemed far, in disarray.\nBut time moves on, as whispers in the wind,\nHint at change, where despair had been pinned.\nThe snow melts away, revealing the ground,\nA symbol of life, soon to be found.\nSpring arrives with a gentle embrace,\nAwakening the earth with its grace.\nFlowers bloom, painting the world anew,\nIn vibrant hues of every hue.\nThe sun breaks through the lingering gloom,\nFilling hearts with warmth, dispelling doom.\nBirds sing songs of joy, so sweet and clear,\nProclaiming the news that happiness is near.\nThis transition, from dark to light,\nReminds us all of the perpetual fight.\nFor after every hardship, there comes ease,\nA cycle of life, meant to appease.\nSo let us welcome spring, with open arms,\nAnd find solace in its charms.\nFor it brings hope, and a fresh start,\nHealing the winter\u0026rsquo;s wounds in our heart.\n","permalink":"https://jonash.xyz/posts/from-darkness-to-light/","summary":"From darkness to light In winter\u0026rsquo;s clutch, the world lay still,\nA canvas painted in shades of chill.\nThe trees stood bare, the skies so gray,\nHope seemed far, in disarray.\nBut time moves on, as whispers in the wind,\nHint at change, where despair had been pinned.\nThe snow melts away, revealing the ground,\nA symbol of life, soon to be found.\nSpring arrives with a gentle embrace,\nAwakening the earth with its grace.","title":"From darkness to light"},{"content":"Understanding DevOps: A Brief Overview DevOps, a compound of development (Dev) and operations (Ops), is a software development and delivery approach that emphasizes communication, collaboration, integration, and automation among software developers and IT operations teams. The goal of DevOps is to improve and speed up the delivery of software applications and services. By fostering a culture where building, testing, and releasing software can happen rapidly, frequently, and more reliably, DevOps has become a key practice in the software industry.\nKey Principles of DevOps Continuous Integration (CI): Developers merge their changes back to the main branch as often as possible. Automated tests run with these integrations to catch bugs quickly.\nContinuous Delivery (CD): This practice involves automatically deploying all code changes to a testing or staging environment after the build stage. It ensures that the software can be reliably released at any time.\nAutomated Testing: Automation in testing reduces manual workload and speeds up the process of software development and deployment.\nInfrastructure as Code (IaC): Managing and provisioning infrastructure through code instead of through manual processes, improving operational efficiency and cloud management.\nMonitoring and Logging: Keeping track of the performance of applications and infrastructure to quickly respond to issues.\nCollaboration and Communication: Encouraging open communication and collaboration within and between teams to enhance the development process.\nBenefits of DevOps Faster Time to Market: Shortened development cycles lead to faster innovation and a quicker time to market.\nImproved Collaboration: Breaking down silos between teams enhances collaboration and efficiency.\nIncreased Efficiency: Automation and streamlined workflows increase the efficiency of the development and deployment processes.\nEnhanced Quality: Continuous integration and delivery ensure that quality is maintained through frequent code updates and testing.\nHigher Customer Satisfaction: Rapid deliveries of updates and new features lead to higher customer satisfaction.\nConclusion DevOps is not just a set of practices but a culture that needs to be adopted for its full potential to be realized. By embracing DevOps, organizations can enhance their ability to deliver applications and services at high velocity, thereby outpacing their competitors in today\u0026rsquo;s fast-paced digital world.\n","permalink":"https://jonash.xyz/posts/what-is-devops/","summary":"Understanding DevOps: A Brief Overview DevOps, a compound of development (Dev) and operations (Ops), is a software development and delivery approach that emphasizes communication, collaboration, integration, and automation among software developers and IT operations teams. The goal of DevOps is to improve and speed up the delivery of software applications and services. By fostering a culture where building, testing, and releasing software can happen rapidly, frequently, and more reliably, DevOps has become a key practice in the software industry.","title":"What Is Devops"},{"content":"","permalink":"https://jonash.xyz/articles/","summary":"articles","title":"Articles"}]